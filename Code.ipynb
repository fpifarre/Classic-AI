{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the way Machine Learning algorithms and Neural Networks work has been explained in the Theoretical Frame, we can proceed to building one. The main goal of this part of the work will be to build a Machine Learning algorithm to generate music. As explained before, Artificial Neural Networks are powerful tools to classify and predict data. Is this ability to predict new data that opens the door for what humans would call \"creativity\", something rather controversial when talking about an Artificial Intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Artificial Neural Networks to immitate human art has been done for some time with success. Let's think about text, for instance. As seen when explaining LSTMs, those can be used to predict the next character in a sequence of text. For instance, a traines LSTM could recieve the following sentence as an input and output the predicted next character for it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[H, E, L, L] -> [O]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, a single character has been generated from a previous sequence, but this is hardly creative. To create a more complex sentence, we would have to keep the LSTM running, giving it as an input the same sequence plus the character it has predicted:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[H, E, L, L, O] -> [   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it predicts a white space to separate this word from a hypothetical next one. But, what if we where to keep the algorithm running in its own predicions? Then it would keep generating characters, and then sentences, and eventually a full text. This text would then have been created by an Artificial Intelligence completely and would be, therefore, original. This task, as simple as it may seem, is actually quite complex. The Network would have to learn by itself how grammar works, how to write words and full sentences only by looking at sample data, which would be full texts in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the complexity of creating an ML algorithm to generate text doesn't only lie on the complexity of the task. Remember that ANNs can only deal with numerical data and text is, obviously, not numerical. This requieres to develop systems to \"translate\" text into numerical values so that the Network can deal with them. And only then, when dealing with numerical data, could the network reach an \"understanding\" of language to generate text by itself. This way to generate text is so abstract that it is hard to say that the Network \"understands\" languange, or that it is \"creative\" to generate completely original pieces. But instead of diving into the task of making clear whether the ML algorithms are creative or can understand something as complex as language, we will focus on building them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, seeing that ANNs are able to generate text, could they generate music?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may think that music and text are completely different from each other, but they are not that different. You could think of musical notes as characters in a text, and of musical pieces as sentences. In fact, both are sequential structures of different elements, either characters or notes. This means that an Artificial Neural Network should be able to predict musical notes as it can predict text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal will be to build a Machine Learnig algorithm to generate music based on a dataset of 80 violin scores from Johann Sebastian Bach, Antonio Vivaldi, Ludwig van Beethoven, Wolfgang Amadeus Mozart and Niccol√≤ Paganini, classical music composers. The 80 scores contain over 40.000 notes which will be the dataset used to train the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ML algorith will be coded in Python 3.6.6 on a Jupyter Notebook enviroment. To extract the music data from their files we will use the music21 library (version 5.3), developed by the MIT and \"os\" to access them in the memory. To preprocess this data and make it numerical we will use Pandas (version 0.23.4) and Numpy (1.14.5), libraries used to manage data and perform operations on it. Finally, we will also use the Tensorflow library (GPU 1.10 version) to build the Artificial Neural Network that will process the data and, eventually, generate new music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Extracting the data from MIDI files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict music the first thing that must be done is extract the training data from its source files. In our case, the source files are MIDI files, gathered from the MuseScore public sheet database. All the files have been saved in the same folder for convinience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated before, there are 80 different files in that folder, so a list of them must be created to extract data from them individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using \"os\", we list add the name of every file in that folder to a list, and then, we add them to the original path so that we can read them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in range(len(files)):\n",
    "    files[file] = path + files[file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of all files, we must extract the musical data from them. To do so, an empty list is created and two values are added to it. The first value will be the note pitch and the second value will be its duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add those values to the list we must first convert the MIDI file to a score object in music21. Once the score object has been created, we check for every note on it and add its pitch and length to the previously created data list. Checking if the current element is a note is done in order to avoid having other musical structures in the data file, such as chords, as this would greately complicate the preprocessing of data and the eventual prediction of music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    score = music21.converter.parse(file)[0]\n",
    "    for note in score.getElementsByClass(\"Note\"):\n",
    "        indv_note = [note.pitch, note.duration.quarterLength]\n",
    "        data.append(indv_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we have a list of all notes in the dataset we can proceed to preprocessing them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data, columns = [\"Note\", \"Duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Note</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F#4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F#4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F#4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Note Duration\n",
       "0  F#4        1\n",
       "1  F#4        1\n",
       "2  F#4        1\n",
       "3   D4        4\n",
       "4   E4        1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41811"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data is of great importance and it can determine the ML algorithms success. As you can see above, we have over 40.000 notes with two features each; their pitch and duration. This are categorical features, meaning that a note can be categorized by its pitch or the musical note it represents and by its duration. This data has to be preprocessed so that it can be used as an input for an ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also now that we define the length of the sequences that will be used later in the network. The sequence length can be descrived as the network's memory. A sequence length of 25 means that the network will take into account the last 25 notes it has seen before predicting the next one. A sequence length too short can lead to the network failing to correctly predict the next note, but a sequence length too long is also not ideal, as it can lead to the network memorizing the prediction from the dataset rather that finding patterns in the data, which would lead to bad results when generating its own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'data_length' (int)\n",
      "Stored 'sequence_length' (int)\n"
     ]
    }
   ],
   "source": [
    "%store data_length\n",
    "%store sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Notes preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = data[\"Note\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    F#4\n",
       "1    F#4\n",
       "2    F#4\n",
       "3     D4\n",
       "4     E4\n",
       "Name: Note, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's preprocess the notes. We will transform them into categorical numerical values, so that they can be used by the network. We will do so by using the one-hot encoding method. A very easy way to visualize how this encoding methon works is looking at the following example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1,2,3] -> [[1,0,0], [0,1,0], [0,0,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, you can see that each value has been given an index in the one-hot encoded array, being as many indexes as categories in the original data. In our case, we have a much higher number of classes (notes), going as high as 54, as seen bellow with the variable \"n_notes\". This means that manually encoding them would requiere a lot of effort. Luckily, Keras packs a one-hot encoder which automatically does what we have manually done in the previous example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real purpose on one-hot encoding will become clearer once we build the Nerual Network that will process the data. Thay are useful because they can be interpreted as a probability distribution. Returning to our example, a one in the second index of the array can be interpreted as a 100% probability of the original value encoded being part of the second category. This probability distribution form will be very useful when trying to predict notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1.1 Notes to categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras function to one-hot encode requieres the data to be in the form of a Numpy ndarray. Numpy ndarrays are n-dimensional arrays, meaning that they store data in a \"n\" number of dimensions. We transform the Pandas Series, the data structure used above, to a Numpy array with the data type being strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = np.asarray(notes, dtype = \"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F#4', 'F#4', 'F#4', ..., 'C5', 'A4', 'C5'], dtype='<U64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_notes = set(notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now list every different note, without them being in the \"all_notes\" list more than once. We do so in order to be able to transform the notes, currently in the form of strings to integers, so that we can one-hot encode them. But before being able to translate them into integers, dictionaries must be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_dictionary = {}\n",
    "notes_dictionary_inv = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for note in all_notes:\n",
    "    notes_dictionary[note] = counter\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for note in all_notes:\n",
    "    notes_dictionary_inv[counter] = note\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two dictionaries are created. The first one translates the string of the note to an integer, while the second one does the opposite; translate an integer to a note in the form of a string. For instance; the note with the identifier 1 corresponds to A6 in musical notation, and another one like B4 has a different integer assigned, 13 in this case. Using this correspondace and this dictionaries, we can proceed to transform the original notes list into integers, so we can later encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_int = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for note in notes:\n",
    "    notes_int.append(notes_dictionary[note])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the notes extracted from the original files in the form of integers, so we can proceed to one-hot encoding them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_preprocessed = tf.keras.utils.to_categorical(notes_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41811, 54)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_preprocessed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a built-in Keras function, one-hot encoding them is very simple. As you can see we end up with two-dimensionalan array consisting of 41.811 items (the total number of notes in the original dataset) with 54 different features per item (the total number of different notes in the dataset). This 54 features per item are actually a one-hot encoded array representing the note, being formed of 53 zeroes and a one. The index of the array where the one is located is the one that gives the array its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_notes = notes_preprocessed.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to finish the notes encoding, we store the total number of different notes, as it will be needed later when defining the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'n_notes' (int)\n",
      "Stored 'notes_dictionary_inv' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store n_notes\n",
    "%store notes_dictionary_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1.2 Notes to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_notes = []\n",
    "outputs_notes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data_length - sequence_length):\n",
    "    sequence = notes_preprocessed[i:i + sequence_length]\n",
    "    following_character = notes_preprocessed[i + sequence_length]\n",
    "    inputs_notes.append(sequence)\n",
    "    outputs_notes.append(following_character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_notes = np.asarray(inputs_notes)\n",
    "labels_notes = np.asarray(outputs_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41786, 25, 54)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_notes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41786, 54)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_notes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to finish the preprocessing of the notes, we must save them in the form of inputs and outputs. This requieres storing the notes in groups of 25, the sequence length we defined previously, or the number of previous notes the Neural Network will store in its memory when it is built. So we take 25 notes and group them together into the \"inputs_notes\" array while we store the next note in the \"outputs_notes\" array, as it is the value the network will try to predict. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we transform these two arrays into ndarrays. The \"features_notes\" ndarray is a three-dimensional array; being the first one the number of samples (the length of the dataset minus the sequence length), the second dimension the length of the sequence, and the third one the number of features in each item, or the total number of different notes. The \"labels_notes\" ndarray has only two dimensions, as it doesn't have a sequence length because of ot corresponding to the output of the network and the network predicting a single note at a time. Here, the first dimension also corresponds to the number of samples, the same as before, and to the total number of different notes, also the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'features_notes' (ndarray)\n",
      "Stored 'labels_notes' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store features_notes\n",
    "%store labels_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Durations preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Note</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F#4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F#4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F#4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Note Duration\n",
       "0  F#4        1\n",
       "1  F#4        1\n",
       "2  F#4        1\n",
       "3   D4        4\n",
       "4   E4        1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But remember that the note was not the only feature that we had. We also have another feature, the duration of the note. To preprocess it, we will do exactly the same as when encoding and preprocessing the notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2.1 Durations to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = data[\"Duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    4\n",
       "4    1\n",
       "Name: Duration, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = np.asarray(durations, dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_durations = set(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_dictionary = {}\n",
    "durations_dictionary_inv = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for duration in all_durations:\n",
    "    durations_dictionary[duration] = counter\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for duration in all_durations:\n",
    "    durations_dictionary_inv[counter] = duration\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_int = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for duration in durations:\n",
    "    notes_int.append(durations_dictionary[duration])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_preprocessed = tf.keras.utils.to_categorical(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_durations = durations_preprocessed.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'n_durations' (int)\n",
      "Stored 'durations_dictionary_inv' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store n_durations\n",
    "%store durations_dictionary_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2.2 Durations to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_durations = []\n",
    "outputs_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data_length - sequence_length):\n",
    "    sequence = durations_preprocessed[i:i + sequence_length]\n",
    "    following_character = durations_preprocessed[i + sequence_length]\n",
    "    inputs_durations.append(sequence)\n",
    "    outputs_durations.append(following_character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_durations = np.asarray(inputs_durations)\n",
    "labels_durations = np.asarray(outputs_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41786, 25, 10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_durations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41786, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_durations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'features_durations' (ndarray)\n",
      "Stored 'labels_durations' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store features_durations\n",
    "%store labels_durations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Creating the networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it comes the time to define the Neural Network that we will use to generate music. Actually, two different networks will be built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But even if building and training two completely different networks, we will use the same optimizar for both of them. If more than one optimizer was used, one for each with different learning rates, better results might be archieved. For simplicity, though, we will use the same optimizer for both networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer in question is the Adam optimizer. This optimizer is build upon Gradient Descent, but is much more complex and effective. The version of this optimizer in Keras is the one proposed by Diederik P. Kingma and Jimmy Lei Ba in their 2015 paper \"Adam: a method for stochastic optimization\". The details of this optimization algorithm will not be descrives as it involves many complex mathematical calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Notes network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_notes = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we define the Keras model that will be used. This will be a sequential model, that is one corresponding to the usual ANN structure. This will be the model tasked with predicting notes, and another one will be later built to predict the durations of those notes. Both models will have be of the same type; Recurrent Neural Network with Long-Short Term Memory cells. This will give the model both a short term memory, the last note predicted by the model, and a long term memory, the last 25 notes predicted by the model (corresponding to the sequence length, as stated before when defining this variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_notes.add(tf.keras.layers.LSTM(128, input_shape = (sequence_length, n_notes), return_sequences = True))\n",
    "network_notes.add(tf.keras.layers.Dropout(0.1))\n",
    "network_notes.add(tf.keras.layers.LSTM(128))\n",
    "network_notes.add(tf.keras.layers.Dropout(0.1))\n",
    "network_notes.add(tf.keras.layers.Dense(n_notes, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 25, 128)           93696     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 54)                6966      \n",
      "=================================================================\n",
      "Total params: 232,246\n",
      "Trainable params: 232,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network_notes.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the model, we will add layers to it. In the first layer, we must specify the shape of its input. This shape would be the equivalent to the Input Layer of the model, as Keras doesn't have an specific Input Layer module. The dimensions of this Input Layer, of the shape of the first Hidden Layer will be the sequnece length and the total number of notes to classify. The layer we add to the model is a LSTM with 128 neurons. We set the parameter \"return_sequences\" to true for the first layer as another LSTM layer will be following. This second LSTM also has 128 neurons. This parameter is needed in order to give the short term memory ability to the second layer of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between the Hidden Layers of the model, we add what Keras calls a Dropout Layer. The dropout layer is the ammount of neurons of the following layers that will not be trained during the current epoch. It represents a percentage; 0.1 actually refers to 10% of the neurons. This means that at each training batch, 10% of the neurons will not be trained. This is done in order to avoid overfitting. Overfitting happens when the network's weights and biases are tuned to much to match the current training batch. It this were to happen, the network would be to fitted to process the training examples, but would not be able to generalize what it has learned to new hypothetical data that it has not processed before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last layer of the netork is a Dense Layer. This is the Output Layer, with the same number of neurons are different types of notes exist in the dataset, and the softmax function is used as the activation function. For the other layer the default activation function (Hyperbolic Tangent) was used. The main characteristic of the softamx function is that it outputs a number of values that sum 1. This means that it essentially outputs a probability distribution. This means that it is ideal to process one-hot encoded sequences, as this sequences also sum 1 (with the index of the value one being the note and the other ones being zero). The network, when used to generate new notes, will output a number of values in each index of the newly formed array. The index with the higher number will be the one the network \"belives\" would be the following one based on its training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up with a RNN with a LSTM structure formed by two Hidden Layers with a Hyperbolic Tangent activation function and an Output Layer with the softmax function. So now we can proceed to training the network on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_notes.compile(loss = \"categorical_crossentropy\", optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training it the last step is compiling it. Doing so requieres to chose a loss function and an optimizer. The loss function used here is Categorical Crossentropy, the one used when the softmax layer is used in the Output Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13d3d7d3518>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_notes.fit(features_notes, labels_notes, batch_size = 100, epochs = 1, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the network with a batch size of 100 examples and for 50 epochs. This takes quite a long time, depending on the computing power of the computer used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_notes = \"Models/notes_model.h5py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_notes.save(save_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'save_notes' (str)\n"
     ]
    }
   ],
   "source": [
    "%store save_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the network to the \"save_notes\" path. Keras allows networks being saved in a custom file format called h5py. This format allows Keras to save networks and later restore them with the exact same structure, weights and biases it had before being saved. In case we were to train the network more, the optimizer for the network and its loss function would also be saves in the same exact state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Durations network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the network that will predict the duration of the notes, the exact same thing as with the network used to predict the notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_durations = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_durations.add(tf.keras.layers.LSTM(128, input_shape = (sequence_length, n_durations), return_sequences = True))\n",
    "network_durations.add(tf.keras.layers.Dropout(0.1))\n",
    "network_durations.add(tf.keras.layers.LSTM(128))\n",
    "network_durations.add(tf.keras.layers.Dropout(0.1))\n",
    "network_durations.add(tf.keras.layers.Dense(n_durations, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_durations.compile(loss = \"categorical_crossentropy\", optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 25, 128)           71168     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 204,042\n",
      "Trainable params: 204,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network_durations.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13d13664fd0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_durations.fit(features_durations, labels_durations, batch_size = 100, epochs = 1, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_durations = \"Models/durations_model.h5py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_durations.save(save_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'save_durations' (str)\n"
     ]
    }
   ],
   "source": [
    "%store save_durations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Generating new melodies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it's time to generate music using the two Neural Networks created and trained. To generate the music, we start importing the same dependencies as before and reading all the stores variables to be able to build some of the data stored during the data preprocessing and network definition and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data_length\n",
    "%store -r sequence_length\n",
    "%store -r n_notes\n",
    "%store -r n_durations\n",
    "%store -r features_notes\n",
    "%store -r features_durations\n",
    "%store -r notes_dictionary_inv\n",
    "%store -r durations_dictionary_inv\n",
    "%store -r save_notes\n",
    "%store -r save_durations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load the two networks using the save created before by Keras using a Keras function and using the file path as its argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_notes = tf.keras.models.load_model(save_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_durations = tf.keras.models.load_model(save_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_to_generate = 500\n",
    "temperature_notes = 0.5\n",
    "temperature_durations = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to define the hyperparamethers of the music generations. Those are three: the number of notes to generate in the variable \"notes_to_generate\" and the temperatures of the two networks. The temperature is a mathematical paramether that changes the output of the softmax function in the Output Layer. The lower the temperature is, the more confident the network will be. More about the temperature and its mathematical expression will be explained when defining the temperature function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_start = np.random.randint(0, data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_notes = features_notes[random_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_durations = features_durations[random_start]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before starting to generate new music, an initial sequence must be loaded from the original dataset. Because of the way the ANN was built, it requieres a sequence before being able to generate new music on its own. This sequence will be loaded from a random point in the original dataset for both the notes dataset and the durations dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for note, duration in zip(sequence_notes, sequence_durations):\n",
    "    notes.append([notes_dictionary_inv[np.argmax(note)], durations_dictionary_inv[np.argmax(duration)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also append this orignial sequence to the newly created \"notes\" array. This array will end up containing every note generated by the algorithm and the original notes serving as the original sequence. To append the sample sequence to the array in the form of a real note and duration, the process followed to encode them must be inverted. We do so using the inverse dicitonaries created when encoding and preprocessing the data and picking the index of the maximum argument in the one-hot encoded array. What we are essentially doing is inverting the preprocessing of the data in order to be able to end having the same items as we stracted from the scoe; a note and its duration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the networks has generated new notes, we will use music21 again to encode the notes in a midi file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_temperature(predictions, temperature = 0.5):\n",
    "    predictions = predictions.astype(\"float\")\n",
    "    predictions = np.log(predictions) / temperature\n",
    "    predictions = np.exp(predictions) / np.sum(np.exp(predictions))\n",
    "    return np.random.multinomial(1, predictions, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, about the temperature. The mathematical formula of the code above is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code does the same as the formula above using numpy's functions por the exponentials and natural logarithm. It returns the predictions modified accordingly to the temperature. This modifications are actually quite simple: if the temperature is smaller than 1, the differences between the different predicted values is made bigger, thus making the network more confident of its predictions and make it output more consistent results with the original dataset. If the temperature is higher than 1, the opposite happens: the differences between the values are made smaller, thus making the network less confident and make it output less consistent results with the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_note():\n",
    "    note_feature = np.reshape(sequence_notes, (1, sequence_length, n_notes))\n",
    "    predicted_note = network_notes.predict(note_feature)[0]\n",
    "    predicted_note_temperature = apply_temperature(predicted_note, temperature = temperature_notes)\n",
    "    final_note = notes_dictionary_inv[np.argmax(predicted_note_temperature)]\n",
    "    sequence_notes = np.concatenate((sequence_notes[1:len(sequence_notes)], predicted_note_temperature), axis = 0)\n",
    "    return final_note, sequence_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_duration():\n",
    "    duration_feature = np.reshape(sequence_durations, (1, sequence_length, n_durations))\n",
    "    predicted_duration = network_durations.predict(duration_feature)[0]\n",
    "    predicted_duration_temperature = apply_temperature(predicted_duration, temperature = temperature_durations)\n",
    "    final_duration = durations_dictionary_inv[np.argmax(predicted_duration_temperature)]\n",
    "    sequence_durations = np.concatenate((sequence_durations[1:len(sequence_durations)], predicted_duration_temperature), axis = 0)\n",
    "    return final_duration, sequence_durations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the funcions to actually use the networks and predict the notes and their durations. First we reshape the sequence to make it fit into the network, and then we use the network to predict values based on that sequence. Once we have the predictions, we apply the temperature function to them and we append the most likely next note and duration to the sequence that will be used in the next epoch, removing the first one at the same time to make sure this sequence always have a length of 25 (the sequence length used all the time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(notes_to_generate):\n",
    "    predict_note()\n",
    "    predict_duration()\n",
    "    new_note = [final_note, final_duration]\n",
    "    notes.append(new_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all that is left is use this functions and append all the predicted notes to the notes array previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = music21.stream.Stream()\n",
    "midi.insert(music21.instrument.Violin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for note in notes:\n",
    "    new_note_midi = music21.note.Note(str(note[0]), quarterLength = float(note[1]))\n",
    "    midi.append(new_note_midi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'song.mid'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi.write(\"midi\", fp = \"song.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, at last, we use music21 to transform those notes into a midi file, so we end with a music file with the same format and structure as the original files in the dataset. And with this new file comes music generated by an AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
